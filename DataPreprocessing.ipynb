{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define input directories\n",
    "base_dir = \"s1\"\n",
    "align_dir = os.path.join(base_dir, \"align\")\n",
    "audio_dir = os.path.join(base_dir, \"audio\")\n",
    "video_dir = os.path.join(base_dir, \"video\")\n",
    "\n",
    "# Define output directories\n",
    "output_dir = \"processed_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "processed_audio_dir = os.path.join(output_dir, \"audio\")\n",
    "processed_video_dir = os.path.join(output_dir, \"video\")\n",
    "processed_align_dir = os.path.join(output_dir, \"align\")\n",
    "\n",
    "os.makedirs(processed_audio_dir, exist_ok=True)\n",
    "os.makedirs(processed_video_dir, exist_ok=True)\n",
    "os.makedirs(processed_align_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing align files: 100%|██████████| 1000/1000 [00:06<00:00, 155.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_align_files(align_dir, output_dir):\n",
    "    for file_name in tqdm(os.listdir(align_dir), desc=\"Processing align files\"):\n",
    "        if file_name.endswith(\".align\"):\n",
    "            input_path = os.path.join(align_dir, file_name)\n",
    "            output_path = os.path.join(output_dir, file_name)\n",
    "            \n",
    "            # Read the align file\n",
    "            with open(input_path, \"r\") as file:\n",
    "                lines = file.readlines()\n",
    "            \n",
    "            # Save the cleaned alignment (if needed, process lines here)\n",
    "            with open(output_path, \"w\") as out_file:\n",
    "                out_file.writelines(lines)\n",
    "    \n",
    "process_align_files(align_dir, processed_align_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process audio files\n",
    "def process_audio_files(audio_dir, output_dir, sample_rate=16000, n_mels=64, max_audio_len=64):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "    for file_name in tqdm(os.listdir(audio_dir), desc=\"Processing audio files\"):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            input_path = os.path.join(audio_dir, file_name)\n",
    "            output_path = os.path.join(output_dir, file_name.replace(\".wav\", \".npy\"))\n",
    "            print(f\"Processing {input_path} -> {output_path}\")  # Debug path\n",
    "\n",
    "            # Load the audio file\n",
    "            audio, sr = librosa.load(input_path, sr=sample_rate, mono=True)\n",
    "\n",
    "            # Extract log-Mel spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "            log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "            # Ensure consistent time steps by truncating or padding\n",
    "            if log_mel_spec.shape[1] > max_audio_len:\n",
    "                log_mel_spec = log_mel_spec[:, :max_audio_len]\n",
    "            else:\n",
    "                pad_width = max_audio_len - log_mel_spec.shape[1]\n",
    "                log_mel_spec = np.pad(log_mel_spec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "            # Normalize to zero mean and unit variance\n",
    "            log_mel_spec = (log_mel_spec - np.mean(log_mel_spec)) / np.std(log_mel_spec)\n",
    "\n",
    "            # Save as .npy file\n",
    "            np.save(output_path, log_mel_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_files(video_dir, output_dir, frame_size=(112, 112), fps=25, max_frames=75):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "    for file_name in tqdm(os.listdir(video_dir), desc=\"Processing video files\"):\n",
    "        if file_name.endswith(\".mpg\"):\n",
    "            input_path = os.path.join(video_dir, file_name)\n",
    "            output_path = os.path.join(output_dir, file_name.replace(\".mpg\", \".npy\"))\n",
    "            print(f\"Processing {input_path} -> {output_path}\")  # Debug path\n",
    "\n",
    "            # Open video file\n",
    "            cap = cv2.VideoCapture(input_path)\n",
    "            frames = []\n",
    "            frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "            step = frame_rate // fps\n",
    "\n",
    "            success, frame = cap.read()\n",
    "            frame_count = 0\n",
    "            while success:\n",
    "                if frame_count % step == 0 and len(frames) < max_frames:\n",
    "                    # Resize frame and normalize pixel values\n",
    "                    frame = cv2.resize(frame, frame_size)\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) / 255.0  # Normalize to [0, 1]\n",
    "                    frames.append(frame)\n",
    "                success, frame = cap.read()\n",
    "                frame_count += 1\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "            # Ensure consistent number of frames\n",
    "            if len(frames) < max_frames:\n",
    "                pad_frames = max_frames - len(frames)\n",
    "                frames.extend([np.zeros((frame_size[0], frame_size[1], 3))] * pad_frames)\n",
    "\n",
    "            # Convert to numpy array and save\n",
    "            frames = np.array(frames)\n",
    "            np.save(output_path, frames)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Audio directory contents:\", os.listdir(audio_dir))\n",
    "print(\"Video directory contents:\", os.listdir(video_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define input directories\n",
    "base_dir = \"s1\"\n",
    "align_dir = os.path.join(base_dir, \"align\")\n",
    "audio_dir = os.path.join(base_dir, \"audio\")\n",
    "video_dir = os.path.join(base_dir, \"video\")\n",
    "\n",
    "# Define output directories\n",
    "output_dir = \"processed_data\"\n",
    "processed_audio_dir = os.path.join(output_dir, \"audio\")\n",
    "processed_video_dir = os.path.join(output_dir, \"video\")\n",
    "\n",
    "os.makedirs(processed_audio_dir, exist_ok=True)\n",
    "os.makedirs(processed_video_dir, exist_ok=True)\n",
    "\n",
    "def process_audio_files(audio_dir, output_dir, sample_rate=16000, n_mels=64, max_audio_len=64):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
    "    print(f\"Audio files to process: {len(audio_files)}\")  # Debugging\n",
    "\n",
    "    for file_name in tqdm(audio_files, desc=\"Processing audio files\"):\n",
    "        input_path = os.path.join(audio_dir, file_name)\n",
    "        output_path = os.path.join(output_dir, file_name.replace(\".wav\", \".npy\"))\n",
    "        print(f\"Processing {input_path} -> {output_path}\")\n",
    "\n",
    "        audio, sr = librosa.load(input_path, sr=sample_rate, mono=True)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "        if log_mel_spec.shape[1] > max_audio_len:\n",
    "            log_mel_spec = log_mel_spec[:, :max_audio_len]\n",
    "        else:\n",
    "            pad_width = max_audio_len - log_mel_spec.shape[1]\n",
    "            log_mel_spec = np.pad(log_mel_spec, ((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "        log_mel_spec = (log_mel_spec - np.mean(log_mel_spec)) / np.std(log_mel_spec)\n",
    "        np.save(output_path, log_mel_spec)\n",
    "\n",
    "def process_video_files(video_dir, output_dir, frame_size=(112, 112), fps=25, max_frames=75):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mpg\")]\n",
    "    print(f\"Video files to process: {len(video_files)}\")  # Debugging\n",
    "\n",
    "    for file_name in tqdm(video_files, desc=\"Processing video files\"):\n",
    "        input_path = os.path.join(video_dir, file_name)\n",
    "        output_path = os.path.join(output_dir, file_name.replace(\".mpg\", \".npy\"))\n",
    "        print(f\"Processing {input_path} -> {output_path}\")\n",
    "\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        frames = []\n",
    "        frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        step = frame_rate // fps\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        frame_count = 0\n",
    "        while success:\n",
    "            if frame_count % step == 0 and len(frames) < max_frames:\n",
    "                frame = cv2.resize(frame, frame_size)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) / 255.0\n",
    "                frames.append(frame)\n",
    "            success, frame = cap.read()\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) < max_frames:\n",
    "            pad_frames = max_frames - len(frames)\n",
    "            frames.extend([np.zeros((frame_size[0], frame_size[1], 3))] * pad_frames)\n",
    "\n",
    "        frames = np.array(frames)\n",
    "        np.save(output_path, frames)\n",
    "\n",
    "# Run the functions with debugging\n",
    "process_audio_files(audio_dir, processed_audio_dir)\n",
    "process_video_files(video_dir, processed_video_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the video and audio files (assuming they are .npy files)\n",
    "video_file = r'D:\\Master Things\\Fall Sem Classes\\Multimodal Learning for Sensing System\\Project_Implemenation\\processed_data\\video\\bbaf2n.npy'\n",
    "audio_file = r'D:\\Master Things\\Fall Sem Classes\\Multimodal Learning for Sensing System\\Project_Implemenation\\processed_data\\audio\\bbaf2n.npy'\n",
    "\n",
    "video_data = np.load(video_file)\n",
    "audio_data = np.load(audio_file)\n",
    "\n",
    "# Print the dimensions of the video and audio data\n",
    "print(\"Video Data Shape:\", video_data.shape)\n",
    "print(\"Audio Data Shape:\", audio_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check video and audio file sets\n",
    "print(\"Video files:\", video_file)\n",
    "print(\"Audio files:\", audio_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 paired keys.\n",
      "Example from training dataset:\n",
      "(tensor([[[[2.3068e-03, 2.3837e-03, 2.4298e-03,  ..., 1.1226e-03,\n",
      "           1.0304e-03, 9.8424e-04],\n",
      "          [1.4610e-03, 1.5686e-03, 1.6455e-03,  ..., 6.6128e-04,\n",
      "           6.6128e-04, 5.8439e-04],\n",
      "          [1.1534e-03, 1.2303e-03, 1.3226e-03,  ..., 5.0750e-04,\n",
      "           4.9212e-04, 4.3060e-04],\n",
      "          ...,\n",
      "          [1.1226e-03, 1.4302e-03, 1.7839e-03,  ..., 1.9992e-04,\n",
      "           1.8454e-04, 1.0765e-04],\n",
      "          [1.8301e-03, 1.6455e-03, 1.3995e-03,  ..., 1.8454e-04,\n",
      "           1.6917e-04, 1.2303e-04],\n",
      "          [1.6917e-03, 1.5532e-03, 1.0765e-03,  ..., 1.3841e-04,\n",
      "           1.5379e-04, 1.3841e-04]],\n",
      "\n",
      "         [[2.3683e-03, 2.4452e-03, 2.4913e-03,  ..., 1.1842e-03,\n",
      "           1.1073e-03, 1.0611e-03],\n",
      "          [1.4456e-03, 1.5379e-03, 1.6148e-03,  ..., 6.7666e-04,\n",
      "           6.3053e-04, 5.9977e-04],\n",
      "          [1.1226e-03, 1.2149e-03, 1.3072e-03,  ..., 5.0750e-04,\n",
      "           5.0750e-04, 4.7674e-04],\n",
      "          ...,\n",
      "          [1.0919e-03, 1.4456e-03, 1.8608e-03,  ..., 1.5379e-04,\n",
      "           1.3841e-04, 1.2303e-04],\n",
      "          [1.7686e-03, 1.6609e-03, 1.3687e-03,  ..., 1.3841e-04,\n",
      "           1.2303e-04, 1.2303e-04],\n",
      "          [1.6609e-03, 1.5379e-03, 1.0765e-03,  ..., 1.0765e-04,\n",
      "           1.0765e-04, 7.6894e-05]],\n",
      "\n",
      "         [[2.3683e-03, 2.4145e-03, 2.4760e-03,  ..., 1.1842e-03,\n",
      "           1.0765e-03, 1.0611e-03],\n",
      "          [1.4302e-03, 1.5532e-03, 1.6148e-03,  ..., 6.7666e-04,\n",
      "           6.4591e-04, 6.1515e-04],\n",
      "          [1.1534e-03, 1.2457e-03, 1.3072e-03,  ..., 5.2288e-04,\n",
      "           5.0750e-04, 5.0750e-04],\n",
      "          ...,\n",
      "          [1.0765e-03, 1.4764e-03, 1.8454e-03,  ..., 1.6917e-04,\n",
      "           1.6917e-04, 1.3841e-04],\n",
      "          [1.7839e-03, 1.5994e-03, 1.3533e-03,  ..., 1.5379e-04,\n",
      "           1.3841e-04, 1.2303e-04],\n",
      "          [1.6455e-03, 1.5686e-03, 1.0765e-03,  ..., 1.2303e-04,\n",
      "           1.0765e-04, 9.2272e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3376e-03, 2.3991e-03, 2.4760e-03,  ..., 1.1842e-03,\n",
      "           1.1073e-03, 1.0611e-03],\n",
      "          [1.4917e-03, 1.5994e-03, 1.6763e-03,  ..., 6.9204e-04,\n",
      "           6.6128e-04, 6.3053e-04],\n",
      "          [1.1995e-03, 1.2611e-03, 1.3226e-03,  ..., 5.2288e-04,\n",
      "           5.3825e-04, 4.9212e-04],\n",
      "          ...,\n",
      "          [1.2149e-03, 1.4917e-03, 1.8762e-03,  ..., 1.8454e-04,\n",
      "           1.6917e-04, 1.5379e-04],\n",
      "          [1.7839e-03, 1.6148e-03, 1.3533e-03,  ..., 1.5379e-04,\n",
      "           1.0765e-04, 1.0765e-04],\n",
      "          [1.7378e-03, 1.5379e-03, 1.0919e-03,  ..., 1.2303e-04,\n",
      "           7.6894e-05, 6.1515e-05]],\n",
      "\n",
      "         [[2.3683e-03, 2.4298e-03, 2.5067e-03,  ..., 1.2149e-03,\n",
      "           1.1226e-03, 1.0611e-03],\n",
      "          [1.4764e-03, 1.5686e-03, 1.6609e-03,  ..., 6.7666e-04,\n",
      "           6.6128e-04, 6.1515e-04],\n",
      "          [1.1995e-03, 1.2764e-03, 1.3226e-03,  ..., 5.6901e-04,\n",
      "           5.3825e-04, 4.7674e-04],\n",
      "          ...,\n",
      "          [1.2457e-03, 1.4917e-03, 1.8608e-03,  ..., 1.8454e-04,\n",
      "           1.0765e-04, 7.6894e-05],\n",
      "          [1.7993e-03, 1.6301e-03, 1.3533e-03,  ..., 1.3841e-04,\n",
      "           1.0765e-04, 7.6894e-05],\n",
      "          [1.6917e-03, 1.5071e-03, 1.0765e-03,  ..., 1.0765e-04,\n",
      "           7.6894e-05, 4.6136e-05]],\n",
      "\n",
      "         [[2.3991e-03, 2.4606e-03, 2.5375e-03,  ..., 1.1995e-03,\n",
      "           1.1073e-03, 1.0458e-03],\n",
      "          [1.4764e-03, 1.5840e-03, 1.6609e-03,  ..., 6.7666e-04,\n",
      "           6.1515e-04, 5.8439e-04],\n",
      "          [1.1995e-03, 1.2764e-03, 1.3226e-03,  ..., 5.0750e-04,\n",
      "           5.0750e-04, 4.6136e-04],\n",
      "          ...,\n",
      "          [1.2149e-03, 1.4610e-03, 1.8608e-03,  ..., 1.8454e-04,\n",
      "           1.6917e-04, 1.2303e-04],\n",
      "          [1.7993e-03, 1.5994e-03, 1.3379e-03,  ..., 1.3841e-04,\n",
      "           1.0765e-04, 9.2272e-05],\n",
      "          [1.6763e-03, 1.5225e-03, 1.0458e-03,  ..., 1.0765e-04,\n",
      "           1.0765e-04, 9.2272e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.5836e-03, 2.6451e-03, 2.7374e-03,  ..., 1.3995e-03,\n",
      "           1.3533e-03, 1.2764e-03],\n",
      "          [3.4448e-03, 3.5217e-03, 3.6294e-03,  ..., 1.8762e-03,\n",
      "           1.7839e-03, 1.7070e-03],\n",
      "          [3.6140e-03, 3.6909e-03, 3.7985e-03,  ..., 2.0300e-03,\n",
      "           1.9377e-03, 1.8608e-03],\n",
      "          ...,\n",
      "          [2.3376e-03, 2.2145e-03, 2.3376e-03,  ..., 1.4764e-03,\n",
      "           1.3995e-03, 1.3226e-03],\n",
      "          [2.5990e-03, 2.1992e-03, 1.8762e-03,  ..., 1.4148e-03,\n",
      "           1.3533e-03, 1.2918e-03],\n",
      "          [1.9377e-03, 1.9839e-03, 1.4456e-03,  ..., 1.3533e-03,\n",
      "           1.3226e-03, 1.2764e-03]],\n",
      "\n",
      "         [[2.5990e-03, 2.6451e-03, 2.7374e-03,  ..., 1.3687e-03,\n",
      "           1.3379e-03, 1.2611e-03],\n",
      "          [3.4602e-03, 3.5217e-03, 3.6294e-03,  ..., 1.8762e-03,\n",
      "           1.8147e-03, 1.7378e-03],\n",
      "          [3.6294e-03, 3.7216e-03, 3.7985e-03,  ..., 2.0146e-03,\n",
      "           1.9531e-03, 1.8762e-03],\n",
      "          ...,\n",
      "          [2.3683e-03, 2.2145e-03, 2.3376e-03,  ..., 1.4456e-03,\n",
      "           1.3995e-03, 1.3379e-03],\n",
      "          [2.5529e-03, 2.1992e-03, 1.8454e-03,  ..., 1.3995e-03,\n",
      "           1.3533e-03, 1.3072e-03],\n",
      "          [1.9685e-03, 1.9839e-03, 1.4456e-03,  ..., 1.3533e-03,\n",
      "           1.3226e-03, 1.2457e-03]],\n",
      "\n",
      "         [[2.5990e-03, 2.6144e-03, 2.7220e-03,  ..., 1.3841e-03,\n",
      "           1.3379e-03, 1.2457e-03],\n",
      "          [3.4448e-03, 3.5217e-03, 3.6294e-03,  ..., 1.8762e-03,\n",
      "           1.7993e-03, 1.7378e-03],\n",
      "          [3.6601e-03, 3.7370e-03, 3.7985e-03,  ..., 1.9992e-03,\n",
      "           1.9377e-03, 1.8608e-03],\n",
      "          ...,\n",
      "          [2.3529e-03, 2.1992e-03, 2.3376e-03,  ..., 1.4456e-03,\n",
      "           1.4148e-03, 1.3533e-03],\n",
      "          [2.5682e-03, 2.1838e-03, 1.8147e-03,  ..., 1.3995e-03,\n",
      "           1.3687e-03, 1.3072e-03],\n",
      "          [1.9531e-03, 1.9839e-03, 1.4456e-03,  ..., 1.3533e-03,\n",
      "           1.3226e-03, 1.2611e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5375e-03, 2.5836e-03, 2.7067e-03,  ..., 1.3533e-03,\n",
      "           1.3226e-03, 1.2457e-03],\n",
      "          [3.4141e-03, 3.4910e-03, 3.6140e-03,  ..., 1.9070e-03,\n",
      "           1.8147e-03, 1.7378e-03],\n",
      "          [3.6448e-03, 3.7063e-03, 3.8139e-03,  ..., 1.9992e-03,\n",
      "           1.9377e-03, 1.8454e-03],\n",
      "          ...,\n",
      "          [2.3991e-03, 2.1992e-03, 2.2760e-03,  ..., 1.4456e-03,\n",
      "           1.4302e-03, 1.3687e-03],\n",
      "          [2.4913e-03, 2.1684e-03, 1.7993e-03,  ..., 1.4148e-03,\n",
      "           1.3687e-03, 1.3226e-03],\n",
      "          [1.9992e-03, 1.8916e-03, 1.4456e-03,  ..., 1.3841e-03,\n",
      "           1.3379e-03, 1.2764e-03]],\n",
      "\n",
      "         [[2.5836e-03, 2.6144e-03, 2.7067e-03,  ..., 1.3687e-03,\n",
      "           1.2918e-03, 1.2303e-03],\n",
      "          [3.4141e-03, 3.5063e-03, 3.6294e-03,  ..., 1.8762e-03,\n",
      "           1.7993e-03, 1.7224e-03],\n",
      "          [3.6140e-03, 3.6755e-03, 3.8139e-03,  ..., 1.9992e-03,\n",
      "           1.9223e-03, 1.8608e-03],\n",
      "          ...,\n",
      "          [2.4760e-03, 2.1376e-03, 2.2607e-03,  ..., 1.4456e-03,\n",
      "           1.3841e-03, 1.3379e-03],\n",
      "          [2.4913e-03, 2.2145e-03, 1.7993e-03,  ..., 1.4148e-03,\n",
      "           1.3687e-03, 1.2918e-03],\n",
      "          [1.9377e-03, 1.8762e-03, 1.4456e-03,  ..., 1.3687e-03,\n",
      "           1.3379e-03, 1.2611e-03]],\n",
      "\n",
      "         [[2.5682e-03, 2.6144e-03, 2.7067e-03,  ..., 1.3687e-03,\n",
      "           1.3533e-03, 1.2611e-03],\n",
      "          [3.3987e-03, 3.4910e-03, 3.6140e-03,  ..., 1.9070e-03,\n",
      "           1.8301e-03, 1.7686e-03],\n",
      "          [3.6140e-03, 3.6755e-03, 3.8139e-03,  ..., 1.9992e-03,\n",
      "           1.9377e-03, 1.8608e-03],\n",
      "          ...,\n",
      "          [2.4913e-03, 2.1223e-03, 2.2914e-03,  ..., 1.4610e-03,\n",
      "           1.4302e-03, 1.3379e-03],\n",
      "          [2.4913e-03, 2.1992e-03, 1.8147e-03,  ..., 1.4148e-03,\n",
      "           1.3687e-03, 1.3072e-03],\n",
      "          [1.9377e-03, 1.8916e-03, 1.4456e-03,  ..., 1.3687e-03,\n",
      "           1.3226e-03, 1.2611e-03]]],\n",
      "\n",
      "\n",
      "        [[[2.8143e-03, 3.1526e-03, 3.2910e-03,  ..., 1.7532e-03,\n",
      "           1.6609e-03, 1.5686e-03],\n",
      "          [3.7216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1684e-03,\n",
      "           2.0761e-03, 1.9839e-03],\n",
      "          [3.8754e-03, 3.9216e-03, 3.9216e-03,  ..., 2.3068e-03,\n",
      "           2.1992e-03, 2.1223e-03],\n",
      "          ...,\n",
      "          [2.6298e-03, 2.3991e-03, 2.4298e-03,  ..., 1.7839e-03,\n",
      "           1.6917e-03, 1.5840e-03],\n",
      "          [2.5067e-03, 2.1838e-03, 1.8762e-03,  ..., 1.7378e-03,\n",
      "           1.6609e-03, 1.5686e-03],\n",
      "          [1.7224e-03, 2.0915e-03, 1.5994e-03,  ..., 1.6917e-03,\n",
      "           1.6301e-03, 1.5686e-03]],\n",
      "\n",
      "         [[2.7528e-03, 3.1065e-03, 3.2449e-03,  ..., 1.6917e-03,\n",
      "           1.6148e-03, 1.5532e-03],\n",
      "          [3.7370e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1530e-03,\n",
      "           2.0454e-03, 1.9839e-03],\n",
      "          [3.8447e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2607e-03,\n",
      "           2.1684e-03, 2.1069e-03],\n",
      "          ...,\n",
      "          [2.5836e-03, 2.3683e-03, 2.3991e-03,  ..., 1.7378e-03,\n",
      "           1.6763e-03, 1.5994e-03],\n",
      "          [2.3683e-03, 2.2453e-03, 1.8454e-03,  ..., 1.6917e-03,\n",
      "           1.6455e-03, 1.5686e-03],\n",
      "          [1.6148e-03, 1.9839e-03, 1.4610e-03,  ..., 1.6301e-03,\n",
      "           1.6148e-03, 1.5225e-03]],\n",
      "\n",
      "         [[2.7528e-03, 3.0757e-03, 3.2449e-03,  ..., 1.6917e-03,\n",
      "           1.6455e-03, 1.5840e-03],\n",
      "          [3.7216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1684e-03,\n",
      "           2.0915e-03, 1.9992e-03],\n",
      "          [3.8754e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2760e-03,\n",
      "           2.1992e-03, 2.1069e-03],\n",
      "          ...,\n",
      "          [2.5682e-03, 2.3837e-03, 2.3837e-03,  ..., 1.7839e-03,\n",
      "           1.7378e-03, 1.6148e-03],\n",
      "          [2.3837e-03, 2.2145e-03, 1.8147e-03,  ..., 1.7378e-03,\n",
      "           1.6609e-03, 1.5840e-03],\n",
      "          [1.6148e-03, 1.9992e-03, 1.4610e-03,  ..., 1.6609e-03,\n",
      "           1.6148e-03, 1.5379e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.7682e-03, 3.0911e-03, 3.2449e-03,  ..., 1.7070e-03,\n",
      "           1.6455e-03, 1.5379e-03],\n",
      "          [3.7524e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1684e-03,\n",
      "           2.1069e-03, 2.0454e-03],\n",
      "          [3.9216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2299e-03,\n",
      "           2.1684e-03, 2.0915e-03],\n",
      "          ...,\n",
      "          [2.5375e-03, 2.3376e-03, 2.3222e-03,  ..., 1.7378e-03,\n",
      "           1.6763e-03, 1.6301e-03],\n",
      "          [2.3068e-03, 2.1530e-03, 1.8147e-03,  ..., 1.6763e-03,\n",
      "           1.6148e-03, 1.5840e-03],\n",
      "          [1.6609e-03, 1.9685e-03, 1.5379e-03,  ..., 1.6455e-03,\n",
      "           1.5840e-03, 1.5379e-03]],\n",
      "\n",
      "         [[2.7682e-03, 3.1219e-03, 3.2295e-03,  ..., 1.7686e-03,\n",
      "           1.7378e-03, 1.6763e-03],\n",
      "          [3.7524e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1684e-03,\n",
      "           2.0915e-03, 2.0300e-03],\n",
      "          [3.9062e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2914e-03,\n",
      "           2.2299e-03, 2.1684e-03],\n",
      "          ...,\n",
      "          [2.6144e-03, 2.2760e-03, 2.3376e-03,  ..., 1.7378e-03,\n",
      "           1.6301e-03, 1.5840e-03],\n",
      "          [2.2453e-03, 2.2145e-03, 1.8147e-03,  ..., 1.6763e-03,\n",
      "           1.6148e-03, 1.5532e-03],\n",
      "          [1.7070e-03, 1.9377e-03, 1.5225e-03,  ..., 1.6301e-03,\n",
      "           1.5840e-03, 1.5225e-03]],\n",
      "\n",
      "         [[2.7682e-03, 3.1373e-03, 3.2295e-03,  ..., 1.7224e-03,\n",
      "           1.6917e-03, 1.6148e-03],\n",
      "          [3.7370e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1684e-03,\n",
      "           2.0300e-03, 1.9685e-03],\n",
      "          [3.9062e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2607e-03,\n",
      "           2.1992e-03, 2.0915e-03],\n",
      "          ...,\n",
      "          [2.6144e-03, 2.2453e-03, 2.3529e-03,  ..., 1.7532e-03,\n",
      "           1.6763e-03, 1.5994e-03],\n",
      "          [2.2607e-03, 2.2145e-03, 1.8454e-03,  ..., 1.6763e-03,\n",
      "           1.6148e-03, 1.5686e-03],\n",
      "          [1.6763e-03, 1.9223e-03, 1.4764e-03,  ..., 1.6301e-03,\n",
      "           1.5840e-03, 1.5379e-03]]]]), tensor([[ 0.2643,  0.0437, -0.2140,  ..., -1.5666, -1.4157, -1.5189],\n",
      "        [ 0.7433,  0.5711,  0.3630,  ..., -0.9939, -0.9014, -1.0071],\n",
      "        [ 0.8125,  0.6442,  1.1035,  ..., -0.8763, -0.8183, -0.9141],\n",
      "        ...,\n",
      "        [ 1.3350,  1.3350,  1.3350,  ...,  1.3350,  1.3350,  1.3350],\n",
      "        [ 1.3350,  1.3350,  1.3350,  ...,  1.3350,  1.3350,  1.3350],\n",
      "        [ 1.3350,  1.3350,  1.3350,  ...,  1.3350,  1.3350,  1.3350]]), tensor(1.))\n",
      "\n",
      "Example from validation dataset:\n",
      "(tensor([[[[2.2607e-03, 2.3529e-03, 2.4145e-03,  ..., 1.1073e-03,\n",
      "           1.0150e-03, 9.8424e-04],\n",
      "          [1.4302e-03, 1.5686e-03, 1.6301e-03,  ..., 6.3053e-04,\n",
      "           5.8439e-04, 5.2288e-04],\n",
      "          [1.1534e-03, 1.2303e-03, 1.3226e-03,  ..., 4.9212e-04,\n",
      "           4.7674e-04, 4.3060e-04],\n",
      "          ...,\n",
      "          [3.2295e-04, 3.8447e-04, 4.1522e-04,  ..., 1.5379e-04,\n",
      "           1.5379e-04, 1.2303e-04],\n",
      "          [3.0757e-04, 3.6909e-04, 4.1522e-04,  ..., 1.3841e-04,\n",
      "           1.5379e-04, 1.2303e-04],\n",
      "          [3.3833e-04, 3.5371e-04, 3.6909e-04,  ..., 1.2303e-04,\n",
      "           1.3841e-04, 1.0765e-04]],\n",
      "\n",
      "         [[2.3222e-03, 2.3991e-03, 2.4760e-03,  ..., 1.1688e-03,\n",
      "           1.1226e-03, 1.0458e-03],\n",
      "          [1.4456e-03, 1.5532e-03, 1.6148e-03,  ..., 6.7666e-04,\n",
      "           6.4591e-04, 5.8439e-04],\n",
      "          [1.1226e-03, 1.1995e-03, 1.2764e-03,  ..., 4.9212e-04,\n",
      "           4.1522e-04, 3.8447e-04],\n",
      "          ...,\n",
      "          [3.2295e-04, 3.6909e-04, 3.8447e-04,  ..., 1.2303e-04,\n",
      "           1.0765e-04, 1.0765e-04],\n",
      "          [2.9220e-04, 3.2295e-04, 3.6909e-04,  ..., 1.0765e-04,\n",
      "           7.6894e-05, 7.6894e-05],\n",
      "          [3.5371e-04, 3.5371e-04, 3.8447e-04,  ..., 7.6894e-05,\n",
      "           7.6894e-05, 7.6894e-05]],\n",
      "\n",
      "         [[2.3837e-03, 2.4145e-03, 2.4760e-03,  ..., 1.1688e-03,\n",
      "           1.1380e-03, 1.0919e-03],\n",
      "          [1.4610e-03, 1.5532e-03, 1.6148e-03,  ..., 6.6128e-04,\n",
      "           6.4591e-04, 5.5363e-04],\n",
      "          [1.1226e-03, 1.1842e-03, 1.2764e-03,  ..., 4.6136e-04,\n",
      "           4.4598e-04, 4.1522e-04],\n",
      "          ...,\n",
      "          [3.3833e-04, 3.5371e-04, 3.6909e-04,  ..., 1.0765e-04,\n",
      "           1.0765e-04, 1.0765e-04],\n",
      "          [2.9220e-04, 3.0757e-04, 3.2295e-04,  ..., 9.2272e-05,\n",
      "           1.0765e-04, 9.2272e-05],\n",
      "          [3.5371e-04, 3.0757e-04, 3.3833e-04,  ..., 7.6894e-05,\n",
      "           7.6894e-05, 7.6894e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.3529e-03, 2.3991e-03, 2.4606e-03,  ..., 1.1380e-03,\n",
      "           1.1073e-03, 1.0765e-03],\n",
      "          [1.4917e-03, 1.5840e-03, 1.6455e-03,  ..., 6.7666e-04,\n",
      "           6.4591e-04, 6.1515e-04],\n",
      "          [1.1534e-03, 1.1995e-03, 1.2764e-03,  ..., 5.0750e-04,\n",
      "           5.0750e-04, 4.4598e-04],\n",
      "          ...,\n",
      "          [3.5371e-04, 3.8447e-04, 3.8447e-04,  ..., 1.3841e-04,\n",
      "           1.0765e-04, 7.6894e-05],\n",
      "          [2.9220e-04, 3.3833e-04, 3.6909e-04,  ..., 1.0765e-04,\n",
      "           1.0765e-04, 9.2272e-05],\n",
      "          [2.6144e-04, 2.9220e-04, 3.2295e-04,  ..., 9.2272e-05,\n",
      "           7.6894e-05, 6.1515e-05]],\n",
      "\n",
      "         [[2.3837e-03, 2.4298e-03, 2.5067e-03,  ..., 1.1534e-03,\n",
      "           1.1073e-03, 1.0611e-03],\n",
      "          [1.4764e-03, 1.5840e-03, 1.6455e-03,  ..., 6.6128e-04,\n",
      "           6.3053e-04, 5.9977e-04],\n",
      "          [1.1534e-03, 1.2149e-03, 1.2764e-03,  ..., 5.2288e-04,\n",
      "           5.0750e-04, 4.7674e-04],\n",
      "          ...,\n",
      "          [3.5371e-04, 3.8447e-04, 3.8447e-04,  ..., 1.6917e-04,\n",
      "           1.6917e-04, 1.5379e-04],\n",
      "          [2.9220e-04, 3.3833e-04, 3.6909e-04,  ..., 1.3841e-04,\n",
      "           1.3841e-04, 1.0765e-04],\n",
      "          [2.6144e-04, 2.9220e-04, 3.2295e-04,  ..., 1.0765e-04,\n",
      "           1.2303e-04, 9.2272e-05]],\n",
      "\n",
      "         [[2.3837e-03, 2.4298e-03, 2.5067e-03,  ..., 1.1688e-03,\n",
      "           1.1226e-03, 1.0611e-03],\n",
      "          [1.4764e-03, 1.5840e-03, 1.6455e-03,  ..., 6.7666e-04,\n",
      "           6.4591e-04, 6.1515e-04],\n",
      "          [1.1534e-03, 1.2149e-03, 1.2764e-03,  ..., 5.0750e-04,\n",
      "           5.0750e-04, 4.6136e-04],\n",
      "          ...,\n",
      "          [3.2295e-04, 3.6909e-04, 3.8447e-04,  ..., 1.5379e-04,\n",
      "           1.6917e-04, 1.2303e-04],\n",
      "          [2.9220e-04, 3.3833e-04, 3.6909e-04,  ..., 1.2303e-04,\n",
      "           9.2272e-05, 7.6894e-05],\n",
      "          [2.7682e-04, 3.0757e-04, 3.2295e-04,  ..., 9.2272e-05,\n",
      "           6.1515e-05, 3.0757e-05]]],\n",
      "\n",
      "\n",
      "        [[[2.5529e-03, 2.5990e-03, 2.7220e-03,  ..., 1.3379e-03,\n",
      "           1.3226e-03, 1.2764e-03],\n",
      "          [3.4141e-03, 3.4910e-03, 3.6140e-03,  ..., 1.8454e-03,\n",
      "           1.7686e-03, 1.7070e-03],\n",
      "          [3.5986e-03, 3.6755e-03, 3.7832e-03,  ..., 1.9839e-03,\n",
      "           1.9070e-03, 1.8454e-03],\n",
      "          ...,\n",
      "          [1.9070e-03, 1.9377e-03, 2.0146e-03,  ..., 1.4302e-03,\n",
      "           1.3687e-03, 1.3379e-03],\n",
      "          [1.8916e-03, 1.9070e-03, 1.9531e-03,  ..., 1.3687e-03,\n",
      "           1.3379e-03, 1.2918e-03],\n",
      "          [1.8762e-03, 1.8762e-03, 1.8916e-03,  ..., 1.3226e-03,\n",
      "           1.3072e-03, 1.2457e-03]],\n",
      "\n",
      "         [[2.5375e-03, 2.5836e-03, 2.7220e-03,  ..., 1.3072e-03,\n",
      "           1.2764e-03, 1.2149e-03],\n",
      "          [3.4141e-03, 3.4910e-03, 3.5986e-03,  ..., 1.8608e-03,\n",
      "           1.8147e-03, 1.7378e-03],\n",
      "          [3.6755e-03, 3.7063e-03, 3.7985e-03,  ..., 1.9839e-03,\n",
      "           1.9070e-03, 1.8301e-03],\n",
      "          ...,\n",
      "          [1.9070e-03, 1.9531e-03, 1.9992e-03,  ..., 1.4302e-03,\n",
      "           1.3687e-03, 1.3226e-03],\n",
      "          [1.8608e-03, 1.8916e-03, 1.9377e-03,  ..., 1.3841e-03,\n",
      "           1.3379e-03, 1.2918e-03],\n",
      "          [1.8147e-03, 1.8608e-03, 1.8916e-03,  ..., 1.3533e-03,\n",
      "           1.3072e-03, 1.2457e-03]],\n",
      "\n",
      "         [[2.5529e-03, 2.5990e-03, 2.7374e-03,  ..., 1.3379e-03,\n",
      "           1.2764e-03, 1.2303e-03],\n",
      "          [3.3987e-03, 3.4910e-03, 3.5986e-03,  ..., 1.8916e-03,\n",
      "           1.8147e-03, 1.7378e-03],\n",
      "          [3.6294e-03, 3.6909e-03, 3.7832e-03,  ..., 1.9839e-03,\n",
      "           1.8762e-03, 1.8454e-03],\n",
      "          ...,\n",
      "          [1.9377e-03, 1.9685e-03, 2.0146e-03,  ..., 1.4148e-03,\n",
      "           1.3687e-03, 1.3226e-03],\n",
      "          [1.8762e-03, 1.9070e-03, 1.9531e-03,  ..., 1.3687e-03,\n",
      "           1.3379e-03, 1.2764e-03],\n",
      "          [1.7993e-03, 1.8608e-03, 1.9223e-03,  ..., 1.3379e-03,\n",
      "           1.3072e-03, 1.2457e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.5529e-03, 2.5836e-03, 2.6913e-03,  ..., 1.3687e-03,\n",
      "           1.2918e-03, 1.2149e-03],\n",
      "          [3.3833e-03, 3.4602e-03, 3.5832e-03,  ..., 1.8916e-03,\n",
      "           1.8301e-03, 1.7532e-03],\n",
      "          [3.6140e-03, 3.6448e-03, 3.7524e-03,  ..., 1.9992e-03,\n",
      "           1.9531e-03, 1.8762e-03],\n",
      "          ...,\n",
      "          [1.9531e-03, 1.9685e-03, 1.9992e-03,  ..., 1.4302e-03,\n",
      "           1.3841e-03, 1.3379e-03],\n",
      "          [1.8916e-03, 1.9223e-03, 1.9685e-03,  ..., 1.3841e-03,\n",
      "           1.3687e-03, 1.3072e-03],\n",
      "          [1.8454e-03, 1.8762e-03, 1.9223e-03,  ..., 1.3533e-03,\n",
      "           1.3379e-03, 1.2764e-03]],\n",
      "\n",
      "         [[2.5375e-03, 2.5836e-03, 2.7067e-03,  ..., 1.3687e-03,\n",
      "           1.3226e-03, 1.2457e-03],\n",
      "          [3.3987e-03, 3.4756e-03, 3.5986e-03,  ..., 1.9070e-03,\n",
      "           1.8147e-03, 1.7378e-03],\n",
      "          [3.6140e-03, 3.6448e-03, 3.7832e-03,  ..., 1.9992e-03,\n",
      "           1.9377e-03, 1.8608e-03],\n",
      "          ...,\n",
      "          [1.9531e-03, 1.9685e-03, 1.9992e-03,  ..., 1.4456e-03,\n",
      "           1.3841e-03, 1.3226e-03],\n",
      "          [1.8916e-03, 1.9223e-03, 1.9685e-03,  ..., 1.3995e-03,\n",
      "           1.3533e-03, 1.2764e-03],\n",
      "          [1.8454e-03, 1.8762e-03, 1.9223e-03,  ..., 1.3687e-03,\n",
      "           1.2918e-03, 1.2303e-03]],\n",
      "\n",
      "         [[2.5375e-03, 2.5836e-03, 2.7067e-03,  ..., 1.3687e-03,\n",
      "           1.3379e-03, 1.2457e-03],\n",
      "          [3.3987e-03, 3.4910e-03, 3.5832e-03,  ..., 1.9070e-03,\n",
      "           1.8301e-03, 1.7378e-03],\n",
      "          [3.6140e-03, 3.6448e-03, 3.7832e-03,  ..., 1.9992e-03,\n",
      "           1.9223e-03, 1.8454e-03],\n",
      "          ...,\n",
      "          [1.9377e-03, 1.9531e-03, 1.9839e-03,  ..., 1.4302e-03,\n",
      "           1.3687e-03, 1.3379e-03],\n",
      "          [1.8916e-03, 1.9223e-03, 1.9685e-03,  ..., 1.3995e-03,\n",
      "           1.3379e-03, 1.2764e-03],\n",
      "          [1.8608e-03, 1.8916e-03, 1.9223e-03,  ..., 1.3687e-03,\n",
      "           1.3072e-03, 1.2303e-03]]],\n",
      "\n",
      "\n",
      "        [[[2.7989e-03, 3.1834e-03, 3.2757e-03,  ..., 1.7993e-03,\n",
      "           1.7532e-03, 1.6917e-03],\n",
      "          [3.7524e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1838e-03,\n",
      "           2.1069e-03, 2.0454e-03],\n",
      "          [3.9216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.3068e-03,\n",
      "           2.2453e-03, 2.1838e-03],\n",
      "          ...,\n",
      "          [2.3222e-03, 2.5067e-03, 2.5375e-03,  ..., 1.7686e-03,\n",
      "           1.6609e-03, 1.6301e-03],\n",
      "          [2.2914e-03, 2.4606e-03, 2.4760e-03,  ..., 1.7070e-03,\n",
      "           1.5994e-03, 1.5686e-03],\n",
      "          [2.2760e-03, 2.4145e-03, 2.3991e-03,  ..., 1.6763e-03,\n",
      "           1.5840e-03, 1.5379e-03]],\n",
      "\n",
      "         [[2.7220e-03, 3.1219e-03, 3.2603e-03,  ..., 1.7378e-03,\n",
      "           1.6917e-03, 1.6301e-03],\n",
      "          [3.7370e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1838e-03,\n",
      "           2.1223e-03, 2.0607e-03],\n",
      "          [3.9216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2607e-03,\n",
      "           2.1530e-03, 2.0915e-03],\n",
      "          ...,\n",
      "          [2.3683e-03, 2.5682e-03, 2.5836e-03,  ..., 1.7070e-03,\n",
      "           1.6455e-03, 1.6148e-03],\n",
      "          [2.2914e-03, 2.5221e-03, 2.5067e-03,  ..., 1.6763e-03,\n",
      "           1.6148e-03, 1.5840e-03],\n",
      "          [2.2914e-03, 2.5067e-03, 2.4913e-03,  ..., 1.6301e-03,\n",
      "           1.5686e-03, 1.5225e-03]],\n",
      "\n",
      "         [[2.7220e-03, 3.1065e-03, 3.2295e-03,  ..., 1.6917e-03,\n",
      "           1.6301e-03, 1.5840e-03],\n",
      "          [3.7370e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1838e-03,\n",
      "           2.1069e-03, 2.0300e-03],\n",
      "          [3.9216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2760e-03,\n",
      "           2.1376e-03, 2.1069e-03],\n",
      "          ...,\n",
      "          [2.2914e-03, 2.5529e-03, 2.5836e-03,  ..., 1.7224e-03,\n",
      "           1.6455e-03, 1.6148e-03],\n",
      "          [2.2145e-03, 2.4913e-03, 2.5067e-03,  ..., 1.6763e-03,\n",
      "           1.6148e-03, 1.5840e-03],\n",
      "          [2.1838e-03, 2.4606e-03, 2.4760e-03,  ..., 1.6455e-03,\n",
      "           1.5994e-03, 1.5532e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.8143e-03, 3.1219e-03, 3.2757e-03,  ..., 1.7532e-03,\n",
      "           1.6609e-03, 1.5994e-03],\n",
      "          [3.7678e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1838e-03,\n",
      "           2.0915e-03, 2.0146e-03],\n",
      "          [3.9216e-03, 3.9216e-03, 3.9216e-03,  ..., 2.3068e-03,\n",
      "           2.2453e-03, 2.1684e-03],\n",
      "          ...,\n",
      "          [2.3529e-03, 2.5529e-03, 2.6144e-03,  ..., 1.7224e-03,\n",
      "           1.6301e-03, 1.5840e-03],\n",
      "          [2.2760e-03, 2.5067e-03, 2.5682e-03,  ..., 1.6917e-03,\n",
      "           1.6148e-03, 1.5686e-03],\n",
      "          [2.2299e-03, 2.4606e-03, 2.5221e-03,  ..., 1.6609e-03,\n",
      "           1.5840e-03, 1.5379e-03]],\n",
      "\n",
      "         [[2.7528e-03, 3.1373e-03, 3.2449e-03,  ..., 1.7070e-03,\n",
      "           1.6763e-03, 1.6148e-03],\n",
      "          [3.7678e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1376e-03,\n",
      "           2.0761e-03, 1.9992e-03],\n",
      "          [3.8754e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2760e-03,\n",
      "           2.2299e-03, 2.1684e-03],\n",
      "          ...,\n",
      "          [2.3529e-03, 2.5529e-03, 2.6144e-03,  ..., 1.7532e-03,\n",
      "           1.6455e-03, 1.5686e-03],\n",
      "          [2.2760e-03, 2.5067e-03, 2.5682e-03,  ..., 1.7070e-03,\n",
      "           1.6301e-03, 1.5379e-03],\n",
      "          [2.2299e-03, 2.4606e-03, 2.5221e-03,  ..., 1.6763e-03,\n",
      "           1.5994e-03, 1.5225e-03]],\n",
      "\n",
      "         [[2.7528e-03, 3.1065e-03, 3.2449e-03,  ..., 1.7224e-03,\n",
      "           1.6917e-03, 1.6148e-03],\n",
      "          [3.7678e-03, 3.9216e-03, 3.9216e-03,  ..., 2.1376e-03,\n",
      "           2.0915e-03, 2.0146e-03],\n",
      "          [3.8754e-03, 3.9216e-03, 3.9216e-03,  ..., 2.2760e-03,\n",
      "           2.2299e-03, 2.1530e-03],\n",
      "          ...,\n",
      "          [2.3222e-03, 2.5375e-03, 2.5990e-03,  ..., 1.7532e-03,\n",
      "           1.7070e-03, 1.6301e-03],\n",
      "          [2.2760e-03, 2.5067e-03, 2.5682e-03,  ..., 1.7224e-03,\n",
      "           1.6609e-03, 1.5994e-03],\n",
      "          [2.2607e-03, 2.4760e-03, 2.5221e-03,  ..., 1.6917e-03,\n",
      "           1.6301e-03, 1.5686e-03]]]]), tensor([[-0.1850, -0.5240, -0.5192,  ..., -1.9185, -1.9185, -1.9185],\n",
      "        [ 0.0666,  0.0660,  0.3972,  ..., -1.3881, -1.3782, -1.5638],\n",
      "        [ 0.3065,  0.5030,  1.0088,  ..., -1.1164, -1.1328, -1.2918],\n",
      "        ...,\n",
      "        [ 1.2256,  1.2256,  1.2256,  ...,  1.2256,  1.2256,  1.2256],\n",
      "        [ 1.2256,  1.2256,  1.2256,  ...,  1.2256,  1.2256,  1.2256],\n",
      "        [ 1.2256,  1.2256,  1.2256,  ...,  1.2256,  1.2256,  1.2256]]), tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "# Define video and audio directories\n",
    "video_dir = r\"D:\\Master Things\\Fall Sem Classes\\Multimodal Learning for Sensing System\\Project_Implemenation\\processed_data\\video\"\n",
    "audio_dir = r\"D:\\Master Things\\Fall Sem Classes\\Multimodal Learning for Sensing System\\Project_Implemenation\\processed_data\\audio\"\n",
    "\n",
    "# Get filenames (without extensions) from both directories\n",
    "video_files = {os.path.splitext(f)[0] for f in os.listdir(video_dir) if f.endswith(\".npy\")}\n",
    "audio_files = {os.path.splitext(f)[0] for f in os.listdir(audio_dir) if f.endswith(\".npy\")}\n",
    "\n",
    "# Find the intersection of video and audio files\n",
    "keys = list(video_files & audio_files)\n",
    "print(f\"Found {len(keys)} paired keys.\")\n",
    "\n",
    "# Dataset class\n",
    "class AVPairDataset(Dataset):\n",
    "    def __init__(self, video_dir, audio_dir, keys, max_frames=75, max_audio_len=64):\n",
    "        self.video_dir = video_dir\n",
    "        self.audio_dir = audio_dir\n",
    "        self.keys = keys\n",
    "        self.max_frames = max_frames\n",
    "        self.max_audio_len = max_audio_len\n",
    "\n",
    "    def preprocess_video(self, video_path):\n",
    "        \"\"\"Load and preprocess video data.\"\"\"\n",
    "        video = np.load(video_path)  # Shape: (frames, height, width, channels)\n",
    "        if video.shape[0] > self.max_frames:\n",
    "            video = video[:self.max_frames]  # Truncate\n",
    "        elif video.shape[0] < self.max_frames:\n",
    "            pad_size = self.max_frames - video.shape[0]\n",
    "            video = np.pad(video, ((0, pad_size), (0, 0), (0, 0), (0, 0)), mode='constant')  # Pad\n",
    "        video = torch.tensor(video, dtype=torch.float32).permute(3, 0, 1, 2)  # To (C, T, H, W)\n",
    "        return video / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    def preprocess_audio(self, audio_path):\n",
    "        \"\"\"Load and preprocess audio data.\"\"\"\n",
    "        audio = np.load(audio_path)  # Shape: (n_mels, time_steps)\n",
    "        audio = torch.tensor(audio, dtype=torch.float32).permute(1, 0)  # To (time_steps, n_mels)\n",
    "        return audio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        video_path = f\"{self.video_dir}/{key}.npy\"\n",
    "        audio_path = f\"{self.audio_dir}/{key}.npy\"\n",
    "\n",
    "        video_emb = self.preprocess_video(video_path)\n",
    "        audio_emb = self.preprocess_audio(audio_path)\n",
    "\n",
    "        # Labels: 1 for matched pairs, 0 for mismatched (dummy here)\n",
    "        label = torch.tensor(1, dtype=torch.float32)\n",
    "        return video_emb, audio_emb, label\n",
    "\n",
    "# Custom collate function\n",
    "def custom_collate(batch):\n",
    "    \"\"\"Custom collate function for padding.\"\"\"\n",
    "    videos, audios, labels = zip(*batch)\n",
    "\n",
    "    # Stack videos (C, T, H, W)\n",
    "    videos = torch.stack(videos)\n",
    "\n",
    "    # Stack audio (T, F) after padding both time steps and features\n",
    "    max_audio_len = max(a.shape[0] for a in audios)  # Maximum time steps\n",
    "    max_features = max(a.shape[1] for a in audios)   # Maximum feature dimension\n",
    "    max_audio_len = max(a.shape[0] for a in audios)  # Time steps\n",
    "    max_features = max(a.shape[1] for a in audios)   # Mel features\n",
    "    audios = torch.stack([\n",
    "    F.pad(a, (0, max_features - a.shape[1], 0, max_audio_len - a.shape[0]))\n",
    "    for a in audios\n",
    "])\n",
    "\n",
    "    # Stack labels\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return videos, audios, labels\n",
    "\n",
    "# Split keys into training and validation sets and test sets\n",
    "train_keys, val_keys = train_test_split(keys, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AVPairDataset(video_dir, audio_dir, train_keys)\n",
    "val_dataset = AVPairDataset(video_dir, audio_dir, val_keys)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# Print an example from each dataset\n",
    "print(\"Example from training dataset:\")\n",
    "print(train_dataset[0])\n",
    "\n",
    "print(\"\\nExample from validation dataset:\")\n",
    "print(val_dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed video feature size: 451584\n",
      "Computed audio feature size: 4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 200/200 [10:30<00:00,  3.15s/it, loss=0.655]\n",
      "Validation: 100%|██████████| 50/50 [00:39<00:00,  1.26it/s, loss=0.652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.6678, Val Loss: 0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 200/200 [09:22<00:00,  2.81s/it, loss=0.624]\n",
      "Validation: 100%|██████████| 50/50 [00:38<00:00,  1.30it/s, loss=0.622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.6398, Val Loss: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 200/200 [09:25<00:00,  2.83s/it, loss=0.595]\n",
      "Validation: 100%|██████████| 50/50 [00:40<00:00,  1.24it/s, loss=0.59] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.6098, Val Loss: 0.5903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 200/200 [09:56<00:00,  2.98s/it, loss=0.568]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.33it/s, loss=0.556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.5780, Val Loss: 0.5564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 200/200 [10:44<00:00,  3.22s/it, loss=0.526]\n",
      "Validation: 100%|██████████| 50/50 [00:40<00:00,  1.23it/s, loss=0.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.5444, Val Loss: 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 200/200 [10:52<00:00,  3.26s/it, loss=0.494]\n",
      "Validation: 100%|██████████| 50/50 [00:41<00:00,  1.21it/s, loss=0.484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.5090, Val Loss: 0.4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 200/200 [10:44<00:00,  3.22s/it, loss=0.458]\n",
      "Validation: 100%|██████████| 50/50 [00:38<00:00,  1.28it/s, loss=0.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.4738, Val Loss: 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 200/200 [11:00<00:00,  3.30s/it, loss=0.42] \n",
      "Validation: 100%|██████████| 50/50 [00:39<00:00,  1.26it/s, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.4387, Val Loss: 0.4139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 200/200 [10:54<00:00,  3.27s/it, loss=0.378]\n",
      "Validation: 100%|██████████| 50/50 [00:41<00:00,  1.20it/s, loss=0.378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.4045, Val Loss: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 200/200 [11:10<00:00,  3.35s/it, loss=0.349]\n",
      "Validation: 100%|██████████| 50/50 [00:36<00:00,  1.37it/s, loss=0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.3708, Val Loss: 0.3460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 200/200 [09:22<00:00,  2.81s/it, loss=0.318]\n",
      "Validation: 100%|██████████| 50/50 [00:36<00:00,  1.39it/s, loss=0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.3368, Val Loss: 0.3139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 200/200 [09:24<00:00,  2.82s/it, loss=0.289]\n",
      "Validation: 100%|██████████| 50/50 [00:36<00:00,  1.39it/s, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.3056, Val Loss: 0.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 200/200 [10:52<00:00,  3.26s/it, loss=0.263]\n",
      "Validation: 100%|██████████| 50/50 [00:38<00:00,  1.29it/s, loss=0.253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.2750, Val Loss: 0.2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 200/200 [10:35<00:00,  3.18s/it, loss=0.234]\n",
      "Validation: 100%|██████████| 50/50 [00:40<00:00,  1.24it/s, loss=0.225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.2489, Val Loss: 0.2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 200/200 [10:35<00:00,  3.18s/it, loss=0.198]\n",
      "Validation: 100%|██████████| 50/50 [00:39<00:00,  1.28it/s, loss=0.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.2209, Val Loss: 0.2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 200/200 [09:26<00:00,  2.83s/it, loss=0.19] \n",
      "Validation: 100%|██████████| 50/50 [00:36<00:00,  1.38it/s, loss=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.1972, Val Loss: 0.1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 200/200 [10:01<00:00,  3.01s/it, loss=0.161]\n",
      "Validation: 100%|██████████| 50/50 [00:42<00:00,  1.19it/s, loss=0.158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.1756, Val Loss: 0.1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 200/200 [10:07<00:00,  3.04s/it, loss=0.138]\n",
      "Validation: 100%|██████████| 50/50 [00:38<00:00,  1.30it/s, loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.1554, Val Loss: 0.1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 200/200 [09:47<00:00,  2.94s/it, loss=0.13] \n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.35it/s, loss=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.1377, Val Loss: 0.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 200/200 [09:40<00:00,  2.90s/it, loss=0.123] \n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.34it/s, loss=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.1222, Val Loss: 0.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 200/200 [09:39<00:00,  2.90s/it, loss=0.116] \n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.35it/s, loss=0.0956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.1077, Val Loss: 0.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 200/200 [09:40<00:00,  2.90s/it, loss=0.0872]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.35it/s, loss=0.0841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0959, Val Loss: 0.0855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 200/200 [09:47<00:00,  2.94s/it, loss=0.0721]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.32it/s, loss=0.074] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.0850, Val Loss: 0.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 200/200 [09:43<00:00,  2.92s/it, loss=0.0729]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.33it/s, loss=0.0651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.0737, Val Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 200/200 [09:44<00:00,  2.92s/it, loss=0.0614]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.33it/s, loss=0.0573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0646, Val Loss: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 200/200 [09:42<00:00,  2.91s/it, loss=0.0576]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.34it/s, loss=0.0504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0571, Val Loss: 0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 200/200 [09:41<00:00,  2.91s/it, loss=0.0409]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.33it/s, loss=0.0444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0505, Val Loss: 0.0454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 200/200 [09:40<00:00,  2.90s/it, loss=0.0422]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.34it/s, loss=0.0391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0445, Val Loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 200/200 [09:47<00:00,  2.94s/it, loss=0.044] \n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.33it/s, loss=0.0344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0392, Val Loss: 0.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 200/200 [09:42<00:00,  2.91s/it, loss=0.0344]\n",
      "Validation: 100%|██████████| 50/50 [00:37<00:00,  1.34it/s, loss=0.0303]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0344, Val Loss: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Get a single batch from train_loader\n",
    "sample_videos, sample_audios, _ = next(iter(train_loader))\n",
    "\n",
    "\"\"\"AVCNN (Audio-Video Convolutional Neural Network) model for determining whether an audio \n",
    "    matches a given video. The model processes both video and audio inputs through separate \n",
    "    convolutional branches, fuses their features, and predicts a binary output (match/mismatch).\"\"\"\n",
    "# Define the AVCNN model\n",
    "class AVCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AVCNN, self).__init__()\n",
    "\n",
    "        # Video Branch - 3D Convolutional Layers\n",
    "        self.video_conv = nn.Sequential(\n",
    "            nn.Conv3d(3, 16, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "            nn.Conv3d(16, 32, kernel_size=(3, 3, 3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2))\n",
    "        )\n",
    "\n",
    "        # Audio Branch - 1D Convolutional Layers\n",
    "        self.audio_conv = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        # Placeholder for FC layers - Will be dynamically defined\n",
    "        self.video_fc = None\n",
    "        self.audio_fc = None\n",
    "        self.attention = None\n",
    "        self.output_layer = None\n",
    "\n",
    "    def define_fc_layers(self, video_feature_size, audio_feature_size):\n",
    "        \"\"\"Define fully connected layers after computing feature sizes.\"\"\"\n",
    "        self.video_fc = nn.Sequential(\n",
    "            nn.Linear(video_feature_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.audio_fc = nn.Sequential(\n",
    "            nn.Linear(audio_feature_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        # Attention and Output Layers\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, video, audio):\n",
    "        # Video processing (3D Convolution)\n",
    "        video = self.video_conv(video)\n",
    "        video = video.view(video.size(0), -1)\n",
    "        video = self.video_fc(video)\n",
    "\n",
    "        # Audio processing (1D Convolution)\n",
    "        audio = self.audio_conv(audio)\n",
    "        audio = audio.view(audio.size(0), -1)\n",
    "        audio = self.audio_fc(audio)\n",
    "\n",
    "        # Concatenate and attention\n",
    "        combined = torch.cat((video, audio), dim=1)\n",
    "        attention = self.attention(combined)\n",
    "\n",
    "        # Output\n",
    "        output = self.output_layer(attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Compute video and audio feature sizes\n",
    "conv_model = AVCNN()\n",
    "\n",
    "# Compute video feature size\n",
    "with torch.no_grad():\n",
    "    video_features = conv_model.video_conv(sample_videos)\n",
    "    video_feature_size = video_features.view(video_features.size(0), -1).size(1)\n",
    "\n",
    "# Compute audio feature size\n",
    "with torch.no_grad():\n",
    "    audio_features = conv_model.audio_conv(sample_audios)\n",
    "    audio_feature_size = audio_features.view(audio_features.size(0), -1).size(1)\n",
    "\n",
    "print(f\"Computed video feature size: {video_feature_size}\")\n",
    "print(f\"Computed audio feature size: {audio_feature_size}\")\n",
    "\n",
    "# Define the model with the computed feature sizes\n",
    "model = AVCNN()\n",
    "model.define_fc_layers(video_feature_size=video_feature_size, audio_feature_size=audio_feature_size)\n",
    "\n",
    "# Move model to device (CPU in this example)\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0000001)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training and Validation\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for videos, audios, labels in train_progress:\n",
    "        videos, audios, labels = videos.to(device), audios.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(videos, audios).squeeze()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        train_progress.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_progress = tqdm(val_loader, desc=\"Validation\")\n",
    "        for videos, audios, labels in val_progress:\n",
    "            videos, audios, labels = videos.to(device), audios.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(videos, audios).squeeze()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "            val_progress.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {total_train_loss / len(train_loader):.4f}, \"\n",
    "          f\"Val Loss: {total_val_loss / len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced model saved to avcnn_model_enhanced.pth\n"
     ]
    }
   ],
   "source": [
    "# Path to save the model\n",
    "save_path = \"avcnn_model_enhanced.pth\"\n",
    "\n",
    "# Save model state, optimizer state, and additional metadata\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),          # Model weights\n",
    "    'optimizer_state_dict': optimizer.state_dict(),  # Optimizer state\n",
    "    'epoch': epoch,                                  # Current epoch\n",
    "    'train_loss': total_train_loss,                  # Last epoch's training loss\n",
    "    'val_loss': total_val_loss,                      # Last epoch's validation loss\n",
    "    'video_feature_size': video_feature_size,        # Video embedding feature size\n",
    "    'audio_feature_size': audio_feature_size,        # Audio embedding feature size\n",
    "    'hyperparameters': {                             # Hyperparameter dictionary\n",
    "        'learning_rate': 0.0000001,\n",
    "        'batch_size': 4,\n",
    "        'num_epochs': 30,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'BCEWithLogitsLoss'\n",
    "    }\n",
    "}, save_path)\n",
    "\n",
    "# Optionally, save the entire model (not recommended for fine-grained control)\n",
    "torch.save(model, \"avcnn_full_model.pth\")\n",
    "\n",
    "print(f\"Enhanced model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# import random\n",
    "# class ProcessedDataDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     Dataset for loading processed audio and video embeddings and creating mismatched pairs.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, video_folder, audio_folder):\n",
    "#         self.video_files = sorted([os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith('.npy')])\n",
    "#         self.audio_files = sorted([os.path.join(audio_folder, f) for f in os.listdir(audio_folder) if f.endswith('.npy')])\n",
    "#         self.mismatched_audio_files = self.generate_mismatched_audio()\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.video_files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         video = np.load(self.video_files[idx])\n",
    "#         audio = np.load(self.mismatched_audio_files[idx])\n",
    "#         original_audio = np.load(self.audio_files[idx])  # For analysis\n",
    "#         return torch.tensor(video, dtype=torch.float32), torch.tensor(audio, dtype=torch.float32), torch.tensor(original_audio, dtype=torch.float32)\n",
    "\n",
    "#     def generate_mismatched_audio(self):\n",
    "#         \"\"\"\n",
    "#         Create mismatched audio embeddings by shuffling the audio file paths.\n",
    "#         \"\"\"\n",
    "#         mismatched_audio = self.audio_files.copy()\n",
    "#         random.shuffle(mismatched_audio)  # Shuffle paths to mismatch pairs\n",
    "#         return mismatched_audio\n",
    "\n",
    "\n",
    "# def prepare_dataloader(video_folder, audio_folder, batch_size=32):\n",
    "#     \"\"\"\n",
    "#     Prepare dataloader from processed data.\n",
    "#     \"\"\"\n",
    "#     dataset = ProcessedDataDataset(video_folder, audio_folder)\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "#     return dataloader\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Paths to processed data\n",
    "#     video_folder = \"processed_data/video\"\n",
    "#     audio_folder = \"processed_data/audio\"\n",
    "\n",
    "#     # Set up device and model\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     # Load the saved state dictionary\n",
    "#     model.load_state_dict(torch.load(r'D:\\Master Things\\Fall Sem Classes\\Multimodal Learning for Sensing System\\Project_Implemenation\\avcnn_model.pth'))\n",
    "\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Prepare dataloader\n",
    "#     dataloader = prepare_dataloader(video_folder, audio_folder, batch_size=32)\n",
    "\n",
    "#     # Analyze mismatched pairs\n",
    "#     mismatched_results = analyze_mismatched_pairs(model, dataloader, device, threshold=0.33)\n",
    "\n",
    "#     # Output results\n",
    "#     for result in mismatched_results:\n",
    "#         print(\"Indices of high-similarity mismatched pairs:\", result['indices'])\n",
    "#         print(\"Similarities:\", result['similarities'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satrajit Ghosh\\AppData\\Local\\Temp\\ipykernel_9952\\1162062999.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('avcnn_model_enhanced.pth', map_location=torch.device('cpu'))  # Adjust device as needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load('avcnn_model_enhanced.pth', map_location=torch.device('cpu'))  # Adjust device as needed\n",
    "\n",
    "# Recreate the model\n",
    "model = AVCNN()\n",
    "\n",
    "# Dynamically define fully connected layers based on the saved feature sizes\n",
    "video_feature_size = checkpoint['video_feature_size']\n",
    "audio_feature_size = checkpoint['audio_feature_size']\n",
    "model.define_fc_layers(video_feature_size, audio_feature_size)\n",
    "\n",
    "# Load the model state dictionary\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating fooling dataset:   0%|          | 0/50 [00:00<?, ?it/s]C:\\Users\\Satrajit Ghosh\\AppData\\Local\\Temp\\ipykernel_9952\\545276349.py:86: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([1, 512])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(audio_embedding, target_embedding)\n",
      "Creating fooling dataset: 100%|██████████| 50/50 [02:18<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 200 fooling pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_fooling_dataset(model, dataloader, device, threshold=0.3, save_dir='fooling_dataset'):\n",
    "    \"\"\"\n",
    "    Create a dataset with mismatched audio-video pairs modified to fool the AV-CNN model.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True);\n",
    "    fooling_pairs = []\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate through mismatched pairs\n",
    "    for videos, audios, labels in tqdm(dataloader, desc=\"Creating fooling dataset\"):\n",
    "        # Move data to device\n",
    "        videos = videos.to(device)\n",
    "        audios = audios.to(device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        with torch.no_grad():  # Use no_grad only for embedding computation\n",
    "            video_embeddings = model.video_fc(\n",
    "                model.video_conv(videos).view(videos.size(0), -1)\n",
    "            )\n",
    "            audio_embeddings = model.audio_fc(\n",
    "                model.audio_conv(audios).view(audios.size(0), -1)\n",
    "            )\n",
    "            \n",
    "            # Compute cosine similarity\n",
    "            cosine_sim = F.cosine_similarity(video_embeddings, audio_embeddings, dim=1)\n",
    "            \n",
    "            # Find mismatched pairs below the similarity threshold\n",
    "            low_sim_indices = (cosine_sim < threshold).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "        for idx in low_sim_indices:\n",
    "            # Modify the audio to make its embedding closer to the video's embedding\n",
    "            original_audio = audios[idx].cpu().numpy()\n",
    "            target_video_embedding = video_embeddings[idx].cpu().numpy()\n",
    "\n",
    "            # Perturb the audio in the feature space\n",
    "            modified_audio = optimize_audio_to_fool(\n",
    "                original_audio, \n",
    "                target_video_embedding, \n",
    "                model, \n",
    "                device\n",
    "            )\n",
    "            \n",
    "            # Save the modified pair\n",
    "            np.save(os.path.join(save_dir, f\"fooling_video_{idx}.npy\"), videos[idx].cpu().numpy())\n",
    "            np.save(os.path.join(save_dir, f\"fooling_audio_{idx}.npy\"), modified_audio)\n",
    "            \n",
    "            fooling_pairs.append({\n",
    "                'video_index': idx.item(),\n",
    "                'modified_audio_path': os.path.join(save_dir, f\"fooling_audio_{idx}.npy\"),\n",
    "                'original_cosine_similarity': cosine_sim[idx].item()\n",
    "            })\n",
    "    \n",
    "    # Save metadata\n",
    "    with open(os.path.join(save_dir, 'fooling_metadata.json'), 'w') as f:\n",
    "        json.dump(fooling_pairs, f)\n",
    "    \n",
    "    return fooling_pairs\n",
    "\n",
    "\n",
    "def optimize_audio_to_fool(original_audio, target_video_embedding, model, device, lr=0.01, steps=100):\n",
    "    \"\"\"\n",
    "    Optimize the audio to fool the model by matching the target video embedding.\n",
    "    \"\"\"\n",
    "    # Convert audio to a torch tensor\n",
    "    audio = torch.tensor(original_audio, dtype=torch.float32, requires_grad=True, device=device)\n",
    "\n",
    "    # Optimizer to modify the audio\n",
    "    optimizer = torch.optim.Adam([audio], lr=lr)\n",
    "\n",
    "    # Model must be in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Iteratively optimize\n",
    "    for _ in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Extract the audio embedding\n",
    "        audio_embedding = model.audio_fc(\n",
    "            model.audio_conv(audio.unsqueeze(0)).view(1, -1)\n",
    "        )\n",
    "        \n",
    "        # Compute the loss (distance to target video embedding)\n",
    "        target_embedding = torch.tensor(target_video_embedding, dtype=torch.float32, device=device)\n",
    "        loss = F.mse_loss(audio_embedding, target_embedding)\n",
    "        \n",
    "        # Backpropagate and update the audio\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Detach and return the modified audio as a numpy array\n",
    "    return audio.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming model, dataloader, and device are defined\n",
    "    fooling_pairs = create_fooling_dataset(\n",
    "        model, \n",
    "        val_loader,  # Use the validation loader for mismatched pairs\n",
    "        device, \n",
    "        threshold=0.8,\n",
    "        save_dir='fooling_dataset'\n",
    "    )\n",
    "    \n",
    "    print(f\"Created {len(fooling_pairs)} fooling pairs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video shape: (3, 75, 112, 112)\n",
      "Video sample data: [[[2.2914265e-03 2.3683200e-03 2.4452135e-03 ... 1.0765091e-03\n",
      "   9.9961564e-04 9.9961564e-04]\n",
      "  [1.4763552e-03 1.5532487e-03 1.6301422e-03 ... 6.1514805e-04\n",
      "   6.4590544e-04 5.9976935e-04]\n",
      "  [1.1226452e-03 1.1995387e-03 1.2456748e-03 ... 4.6136102e-04\n",
      "   4.3060363e-04 4.1522493e-04]\n",
      "  ...\n",
      "  [3.0757402e-04 3.9984621e-04 4.1522493e-04 ... 1.5378701e-04\n",
      "   1.3840832e-04 1.3840832e-04]\n",
      "  [3.3833142e-04 3.6908881e-04 3.8446751e-04 ... 1.2302962e-04\n",
      "   1.2302962e-04 1.2302962e-04]\n",
      "  [3.5371011e-04 3.6908881e-04 4.4598232e-04 ... 9.2272203e-05\n",
      "   9.2272203e-05 7.6893506e-05]]\n",
      "\n",
      " [[2.3529413e-03 2.4298348e-03 2.4913496e-03 ... 1.1841600e-03\n",
      "   1.0611304e-03 1.0457517e-03]\n",
      "  [1.4609765e-03 1.5532487e-03 1.6147635e-03 ... 6.3052675e-04\n",
      "   5.9976935e-04 5.5363326e-04]\n",
      "  [1.1841600e-03 1.2149174e-03 1.2610535e-03 ... 5.0749717e-04\n",
      "   4.7673972e-04 4.3060363e-04]\n",
      "  ...\n",
      "  [3.3833142e-04 4.4598232e-04 3.3833142e-04 ... 1.3840832e-04\n",
      "   9.2272203e-05 7.6893506e-05]\n",
      "  [3.6908881e-04 3.8446751e-04 3.5371011e-04 ... 1.0765091e-04\n",
      "   1.0765091e-04 9.2272203e-05]\n",
      "  [3.6908881e-04 4.1522493e-04 3.5371011e-04 ... 9.2272203e-05\n",
      "   7.6893506e-05 7.6893506e-05]]\n",
      "\n",
      " [[2.3529413e-03 2.4298348e-03 2.4913496e-03 ... 1.1995387e-03\n",
      "   1.0918878e-03 1.0457517e-03]\n",
      "  [1.4609765e-03 1.5532487e-03 1.6147635e-03 ... 6.7666284e-04\n",
      "   6.4590544e-04 6.1514805e-04]\n",
      "  [1.1841600e-03 1.2149174e-03 1.2610535e-03 ... 5.2287587e-04\n",
      "   5.0749717e-04 4.7673972e-04]\n",
      "  ...\n",
      "  [3.2295272e-04 4.3060363e-04 3.5371011e-04 ... 1.3840832e-04\n",
      "   1.0765091e-04 7.6893506e-05]\n",
      "  [3.0757402e-04 3.5371011e-04 3.3833142e-04 ... 9.2272203e-05\n",
      "   1.0765091e-04 6.1514809e-05]\n",
      "  [3.3833142e-04 3.9984621e-04 3.6908881e-04 ... 7.6893506e-05\n",
      "   6.1514809e-05 6.1514809e-05]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.3068052e-03 2.3836987e-03 2.4605922e-03 ... 1.1380239e-03\n",
      "   1.1380239e-03 1.0765091e-03]\n",
      "  [1.4455979e-03 1.5224913e-03 1.5993848e-03 ... 6.3052675e-04\n",
      "   6.3052675e-04 5.9976935e-04]\n",
      "  [1.0765091e-03 1.1841600e-03 1.2764322e-03 ... 4.6136102e-04\n",
      "   4.7673972e-04 4.3060363e-04]\n",
      "  ...\n",
      "  [3.5371011e-04 3.9984621e-04 3.8446751e-04 ... 1.2302962e-04\n",
      "   9.2272203e-05 4.6136101e-05]\n",
      "  [3.2295272e-04 3.6908881e-04 3.6908881e-04 ... 1.0765091e-04\n",
      "   9.2272203e-05 4.6136101e-05]\n",
      "  [3.5371011e-04 3.5371011e-04 3.3833142e-04 ... 9.2272203e-05\n",
      "   6.1514809e-05 3.0757405e-05]]\n",
      "\n",
      " [[2.3529413e-03 2.4144561e-03 2.4605922e-03 ... 1.1534026e-03\n",
      "   1.0611304e-03 1.0457517e-03]\n",
      "  [1.4302192e-03 1.5224913e-03 1.5840061e-03 ... 6.4590544e-04\n",
      "   6.6128414e-04 6.1514805e-04]\n",
      "  [1.1226452e-03 1.1995387e-03 1.2456748e-03 ... 4.7673972e-04\n",
      "   4.9211847e-04 4.6136102e-04]\n",
      "  ...\n",
      "  [3.6908881e-04 3.5371011e-04 3.6908881e-04 ... 1.0765091e-04\n",
      "   7.6893506e-05 6.1514809e-05]\n",
      "  [3.5371011e-04 3.3833142e-04 3.5371011e-04 ... 1.0765091e-04\n",
      "   9.2272203e-05 3.0757405e-05]\n",
      "  [3.5371011e-04 3.3833142e-04 3.0757402e-04 ... 7.6893506e-05\n",
      "   7.6893506e-05 4.6136101e-05]]\n",
      "\n",
      " [[2.3683200e-03 2.4298348e-03 2.4913496e-03 ... 1.1687813e-03\n",
      "   1.0918878e-03 1.0611304e-03]\n",
      "  [1.4302192e-03 1.5378700e-03 1.5840061e-03 ... 6.6128414e-04\n",
      "   6.4590544e-04 5.8439065e-04]\n",
      "  [1.1072665e-03 1.1995387e-03 1.2456748e-03 ... 4.9211847e-04\n",
      "   4.6136102e-04 3.9984621e-04]\n",
      "  ...\n",
      "  [3.2295272e-04 3.0757402e-04 3.6908881e-04 ... 1.0765091e-04\n",
      "   1.2302962e-04 1.0765091e-04]\n",
      "  [3.2295272e-04 3.0757402e-04 3.0757402e-04 ... 9.2272203e-05\n",
      "   9.2272203e-05 7.6893506e-05]\n",
      "  [2.7681663e-04 2.6143793e-04 3.0757402e-04 ... 6.1514809e-05\n",
      "   6.1514809e-05 6.1514809e-05]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "video = np.load(\"fooling_dataset/fooling_video_0.npy\")\n",
    "print(f\"Video shape: {video.shape}\")\n",
    "print(f\"Video sample data: {video[0]}\")  # Print the first frame to confirm structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio shape: (64, 64)\n",
      "Audio sample data: [ 0.5690439   0.3060006  -0.4027624  -0.5581438  -0.27529022 -0.98442984\n",
      " -1.0474281  -0.1831696  -1.9720982   0.03395173 -1.801744   -2.0140176\n",
      " -1.6376331  -1.3969588  -0.9149329  -0.32539645 -1.9988083  -1.8751271\n",
      " -1.9493237  -1.618401   -0.47617564 -1.0189016  -1.0133573  -1.7131677\n",
      " -1.6634625  -1.4020159  -1.4389524  -2.3380647  -2.187154   -0.6875925\n",
      " -2.1838446  -0.86038035 -1.4020622  -1.7221541  -0.43021744 -1.2077801\n",
      " -2.3443549  -2.25693    -2.5049844  -2.3700016  -2.3611977  -1.528633\n",
      " -2.4078174  -1.9838649  -0.7945519  -1.0691438  -2.1457632  -1.4160042\n",
      " -1.6807576  -1.2642359  -2.4729373  -2.3075347  -1.2190932  -0.9308915\n",
      " -1.253663   -1.4077086  -1.8701073  -1.5378152  -2.9022608  -2.8946996\n",
      " -0.9372429  -1.5319929  -2.4190564  -2.6423523 ]\n",
      "Video shape: (3, 75, 112, 112)\n",
      "Video sample data: [[[2.2914265e-03 2.3683200e-03 2.4452135e-03 ... 1.0765091e-03\n",
      "   9.9961564e-04 9.9961564e-04]\n",
      "  [1.4763552e-03 1.5532487e-03 1.6301422e-03 ... 6.1514805e-04\n",
      "   6.4590544e-04 5.9976935e-04]\n",
      "  [1.1226452e-03 1.1995387e-03 1.2456748e-03 ... 4.6136102e-04\n",
      "   4.3060363e-04 4.1522493e-04]\n",
      "  ...\n",
      "  [3.0757402e-04 3.9984621e-04 4.1522493e-04 ... 1.5378701e-04\n",
      "   1.3840832e-04 1.3840832e-04]\n",
      "  [3.3833142e-04 3.6908881e-04 3.8446751e-04 ... 1.2302962e-04\n",
      "   1.2302962e-04 1.2302962e-04]\n",
      "  [3.5371011e-04 3.6908881e-04 4.4598232e-04 ... 9.2272203e-05\n",
      "   9.2272203e-05 7.6893506e-05]]\n",
      "\n",
      " [[2.3529413e-03 2.4298348e-03 2.4913496e-03 ... 1.1841600e-03\n",
      "   1.0611304e-03 1.0457517e-03]\n",
      "  [1.4609765e-03 1.5532487e-03 1.6147635e-03 ... 6.3052675e-04\n",
      "   5.9976935e-04 5.5363326e-04]\n",
      "  [1.1841600e-03 1.2149174e-03 1.2610535e-03 ... 5.0749717e-04\n",
      "   4.7673972e-04 4.3060363e-04]\n",
      "  ...\n",
      "  [3.3833142e-04 4.4598232e-04 3.3833142e-04 ... 1.3840832e-04\n",
      "   9.2272203e-05 7.6893506e-05]\n",
      "  [3.6908881e-04 3.8446751e-04 3.5371011e-04 ... 1.0765091e-04\n",
      "   1.0765091e-04 9.2272203e-05]\n",
      "  [3.6908881e-04 4.1522493e-04 3.5371011e-04 ... 9.2272203e-05\n",
      "   7.6893506e-05 7.6893506e-05]]\n",
      "\n",
      " [[2.3529413e-03 2.4298348e-03 2.4913496e-03 ... 1.1995387e-03\n",
      "   1.0918878e-03 1.0457517e-03]\n",
      "  [1.4609765e-03 1.5532487e-03 1.6147635e-03 ... 6.7666284e-04\n",
      "   6.4590544e-04 6.1514805e-04]\n",
      "  [1.1841600e-03 1.2149174e-03 1.2610535e-03 ... 5.2287587e-04\n",
      "   5.0749717e-04 4.7673972e-04]\n",
      "  ...\n",
      "  [3.2295272e-04 4.3060363e-04 3.5371011e-04 ... 1.3840832e-04\n",
      "   1.0765091e-04 7.6893506e-05]\n",
      "  [3.0757402e-04 3.5371011e-04 3.3833142e-04 ... 9.2272203e-05\n",
      "   1.0765091e-04 6.1514809e-05]\n",
      "  [3.3833142e-04 3.9984621e-04 3.6908881e-04 ... 7.6893506e-05\n",
      "   6.1514809e-05 6.1514809e-05]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.3068052e-03 2.3836987e-03 2.4605922e-03 ... 1.1380239e-03\n",
      "   1.1380239e-03 1.0765091e-03]\n",
      "  [1.4455979e-03 1.5224913e-03 1.5993848e-03 ... 6.3052675e-04\n",
      "   6.3052675e-04 5.9976935e-04]\n",
      "  [1.0765091e-03 1.1841600e-03 1.2764322e-03 ... 4.6136102e-04\n",
      "   4.7673972e-04 4.3060363e-04]\n",
      "  ...\n",
      "  [3.5371011e-04 3.9984621e-04 3.8446751e-04 ... 1.2302962e-04\n",
      "   9.2272203e-05 4.6136101e-05]\n",
      "  [3.2295272e-04 3.6908881e-04 3.6908881e-04 ... 1.0765091e-04\n",
      "   9.2272203e-05 4.6136101e-05]\n",
      "  [3.5371011e-04 3.5371011e-04 3.3833142e-04 ... 9.2272203e-05\n",
      "   6.1514809e-05 3.0757405e-05]]\n",
      "\n",
      " [[2.3529413e-03 2.4144561e-03 2.4605922e-03 ... 1.1534026e-03\n",
      "   1.0611304e-03 1.0457517e-03]\n",
      "  [1.4302192e-03 1.5224913e-03 1.5840061e-03 ... 6.4590544e-04\n",
      "   6.6128414e-04 6.1514805e-04]\n",
      "  [1.1226452e-03 1.1995387e-03 1.2456748e-03 ... 4.7673972e-04\n",
      "   4.9211847e-04 4.6136102e-04]\n",
      "  ...\n",
      "  [3.6908881e-04 3.5371011e-04 3.6908881e-04 ... 1.0765091e-04\n",
      "   7.6893506e-05 6.1514809e-05]\n",
      "  [3.5371011e-04 3.3833142e-04 3.5371011e-04 ... 1.0765091e-04\n",
      "   9.2272203e-05 3.0757405e-05]\n",
      "  [3.5371011e-04 3.3833142e-04 3.0757402e-04 ... 7.6893506e-05\n",
      "   7.6893506e-05 4.6136101e-05]]\n",
      "\n",
      " [[2.3683200e-03 2.4298348e-03 2.4913496e-03 ... 1.1687813e-03\n",
      "   1.0918878e-03 1.0611304e-03]\n",
      "  [1.4302192e-03 1.5378700e-03 1.5840061e-03 ... 6.6128414e-04\n",
      "   6.4590544e-04 5.8439065e-04]\n",
      "  [1.1072665e-03 1.1995387e-03 1.2456748e-03 ... 4.9211847e-04\n",
      "   4.6136102e-04 3.9984621e-04]\n",
      "  ...\n",
      "  [3.2295272e-04 3.0757402e-04 3.6908881e-04 ... 1.0765091e-04\n",
      "   1.2302962e-04 1.0765091e-04]\n",
      "  [3.2295272e-04 3.0757402e-04 3.0757402e-04 ... 9.2272203e-05\n",
      "   9.2272203e-05 7.6893506e-05]\n",
      "  [2.7681663e-04 2.6143793e-04 3.0757402e-04 ... 6.1514809e-05\n",
      "   6.1514809e-05 6.1514809e-05]]]\n",
      "Number of fooling pairs: 200\n",
      "Fooling pair metadata: {'video_index': 0, 'modified_audio_path': 'fooling_dataset\\\\fooling_audio_0.npy', 'original_cosine_similarity': 0.3061791658401489}\n"
     ]
    }
   ],
   "source": [
    "audio = np.load(\"fooling_dataset/fooling_audio_0.npy\")\n",
    "print(f\"Audio shape: {audio.shape}\")\n",
    "print(f\"Audio sample data: {audio[0]}\")  # Print the first audio frame to confirm structure\n",
    "video = np.load(\"fooling_dataset/fooling_video_0.npy\")\n",
    "print(f\"Video shape: {video.shape}\")\n",
    "print(f\"Video sample data: {video[0]}\")  # Print the first frame to confirm structure\n",
    "metadata = json.load(open(\"fooling_dataset/fooling_metadata.json\"))\n",
    "print(f\"Number of fooling pairs: {len(metadata)}\")\n",
    "print(f\"Fooling pair metadata: {metadata[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satrajit Ghosh\\AppData\\Local\\Temp\\ipykernel_9952\\739366153.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing fooling dataset: 100%|██████████| 200/200 [00:34<00:00,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to fooling_results.json\n",
      "Total fooling pairs: 200\n",
      "Model fooled rate: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the trained model checkpoint\n",
    "model_path = \"avcnn_model_enhanced.pth\"\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Dynamically define fully connected layers based on checkpoint feature sizes\n",
    "video_feature_size = checkpoint['video_feature_size']\n",
    "audio_feature_size = checkpoint['audio_feature_size']\n",
    "\n",
    "# Reinitialize the model with correct feature sizes\n",
    "model = AVCNN()\n",
    "model.define_fc_layers(video_feature_size=video_feature_size, audio_feature_size=audio_feature_size)\n",
    "\n",
    "# Load the model state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Load fooling metadata\n",
    "fooling_metadata_path = \"fooling_dataset/fooling_metadata.json\"\n",
    "with open(fooling_metadata_path, \"r\") as f:\n",
    "    fooling_metadata = json.load(f)\n",
    "\n",
    "# Directory containing the fooling dataset\n",
    "fooling_dataset_dir = \"fooling_dataset\"\n",
    "\n",
    "# Function to load video and audio\n",
    "def load_fooling_pair(video_index, audio_path, dataset_dir):\n",
    "    video_path = f\"{dataset_dir}/fooling_video_{video_index}.npy\"\n",
    "    video_data = np.load(video_path)\n",
    "    audio_data = np.load(audio_path)\n",
    "    video_tensor = torch.tensor(video_data, dtype=torch.float32).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    audio_tensor = torch.tensor(audio_data, dtype=torch.float32).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    return video_tensor, audio_tensor\n",
    "\n",
    "# Test the model with the fooling data\n",
    "results = []\n",
    "for pair in tqdm(fooling_metadata, desc=\"Testing fooling dataset\"):\n",
    "    video_index = pair['video_index']\n",
    "    audio_path = pair['modified_audio_path']\n",
    "    original_similarity = pair['original_cosine_similarity']\n",
    "\n",
    "    # Load video and audio\n",
    "    video_tensor, audio_tensor = load_fooling_pair(video_index, audio_path, fooling_dataset_dir)\n",
    "\n",
    "    # Model prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(video_tensor, audio_tensor).squeeze().sigmoid().item()  # Sigmoid to convert logits to probability\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"video_index\": video_index,\n",
    "        \"modified_audio_path\": audio_path,\n",
    "        \"original_cosine_similarity\": original_similarity,\n",
    "        \"model_prediction\": output,\n",
    "    })\n",
    "\n",
    "# Save results to a JSON file\n",
    "results_path = \"fooling_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "print(f\"Results saved to {results_path}\")\n",
    "\n",
    "# Analysis: McGurk Effect evaluation\n",
    "total_fooling_pairs = len(results)\n",
    "fooling_predictions = [res for res in results if res['model_prediction'] > 0.5]  # Threshold for match\n",
    "fooling_rate = len(fooling_predictions) / total_fooling_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satrajit Ghosh\\AppData\\Local\\Temp\\ipykernel_9952\\1225073974.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing fooling dataset: 100%|██████████| 200/200 [00:41<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to fooling_results.json\n",
      "\n",
      "Analyzing results with multiple thresholds...\n",
      "Threshold: 0.40, Fooling Rate: 100.00%\n",
      "Threshold: 0.50, Fooling Rate: 100.00%\n",
      "Threshold: 0.60, Fooling Rate: 100.00%\n",
      "Threshold: 0.70, Fooling Rate: 100.00%\n",
      "Threshold: 0.80, Fooling Rate: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the trained model checkpoint\n",
    "model_path = \"avcnn_model_enhanced.pth\"\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "# Dynamically define fully connected layers based on checkpoint feature sizes\n",
    "video_feature_size = checkpoint['video_feature_size']\n",
    "audio_feature_size = checkpoint['audio_feature_size']\n",
    "\n",
    "# Reinitialize the model with correct feature sizes\n",
    "model = AVCNN()\n",
    "model.define_fc_layers(video_feature_size=video_feature_size, audio_feature_size=audio_feature_size)\n",
    "\n",
    "# Load the model state dict\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Load fooling metadata\n",
    "fooling_metadata_path = \"fooling_dataset/fooling_metadata.json\"\n",
    "with open(fooling_metadata_path, \"r\") as f:\n",
    "    fooling_metadata = json.load(f)\n",
    "\n",
    "# Directory containing the fooling dataset\n",
    "fooling_dataset_dir = \"fooling_dataset\"\n",
    "\n",
    "# Function to load video and audio\n",
    "def load_fooling_pair(video_index, audio_path, dataset_dir):\n",
    "    video_path = f\"{dataset_dir}/fooling_video_{video_index}.npy\"\n",
    "    video_data = np.load(video_path)\n",
    "    audio_data = np.load(audio_path)\n",
    "    video_tensor = torch.tensor(video_data, dtype=torch.float32).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    audio_tensor = torch.tensor(audio_data, dtype=torch.float32).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    return video_tensor, audio_tensor\n",
    "\n",
    "# Test the model with the fooling data\n",
    "results = []\n",
    "for pair in tqdm(fooling_metadata, desc=\"Testing fooling dataset\"):\n",
    "    video_index = pair['video_index']\n",
    "    audio_path = pair['modified_audio_path']\n",
    "    original_similarity = pair['original_cosine_similarity']\n",
    "\n",
    "    # Load video and audio\n",
    "    video_tensor, audio_tensor = load_fooling_pair(video_index, audio_path, fooling_dataset_dir)\n",
    "\n",
    "    # Model prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(video_tensor, audio_tensor).squeeze().sigmoid().item()  # Sigmoid to convert logits to probability\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"video_index\": video_index,\n",
    "        \"modified_audio_path\": audio_path,\n",
    "        \"original_cosine_similarity\": original_similarity,\n",
    "        \"model_prediction\": output,\n",
    "    })\n",
    "\n",
    "# Save results to a JSON file\n",
    "results_path = \"fooling_results.json\"\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "print(f\"Results saved to {results_path}\")\n",
    "\n",
    "# Analysis: McGurk Effect evaluation\n",
    "print(\"\\nAnalyzing results with multiple thresholds...\")\n",
    "thresholds = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "fooling_rates = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    fooling_predictions = [res for res in results if res['model_prediction'] > threshold]\n",
    "    fooling_rate = len(fooling_predictions) / len(results)\n",
    "    fooling_rates.append(fooling_rate)\n",
    "    print(f\"Threshold: {threshold:.2f}, Fooling Rate: {fooling_rate:.2%}\")\n",
    "\n",
    "# Scatter plot for predictions vs. cosine similarity\n",
    "predictions = [res['model_prediction'] for res in results]\n",
    "cosine_similarities = [res['original_cosine_similarity'] for res in results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cosine_similarities, predictions, alpha=0.5)\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', label='Threshold: 0.5')\n",
    "plt.title(\"Model Predictions vs. Original Cosine Similarities\")\n",
    "plt.xlabel(\"Original Cosine Similarity\")\n",
    "plt.ylabel(\"Model Prediction\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
